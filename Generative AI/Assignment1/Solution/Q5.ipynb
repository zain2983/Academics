{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":23498,"sourceType":"datasetVersion","datasetId":310}],"dockerImageVersionId":30886,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-20T17:02:51.395572Z","iopub.execute_input":"2025-02-20T17:02:51.396089Z","iopub.status.idle":"2025-02-20T17:02:51.405071Z","shell.execute_reply.started":"2025-02-20T17:02:51.396059Z","shell.execute_reply":"2025-02-20T17:02:51.403639Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/creditcardfraud/creditcard.csv\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.preprocessing import StandardScaler\nimport numpy as np","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Read file\ndf=pd.read_csv('/kaggle/input/creditcardfraud/creditcard.csv')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T17:02:56.163720Z","iopub.execute_input":"2025-02-20T17:02:56.164068Z","iopub.status.idle":"2025-02-20T17:03:01.120707Z","shell.execute_reply.started":"2025-02-20T17:02:56.164042Z","shell.execute_reply":"2025-02-20T17:03:01.119602Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"print(df.head)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T17:03:55.684620Z","iopub.execute_input":"2025-02-20T17:03:55.685022Z","iopub.status.idle":"2025-02-20T17:03:55.747974Z","shell.execute_reply.started":"2025-02-20T17:03:55.684991Z","shell.execute_reply":"2025-02-20T17:03:55.746372Z"}},"outputs":[{"name":"stdout","text":"<bound method NDFrame.head of             Time         V1         V2        V3        V4        V5  \\\n0            0.0  -1.359807  -0.072781  2.536347  1.378155 -0.338321   \n1            0.0   1.191857   0.266151  0.166480  0.448154  0.060018   \n2            1.0  -1.358354  -1.340163  1.773209  0.379780 -0.503198   \n3            1.0  -0.966272  -0.185226  1.792993 -0.863291 -0.010309   \n4            2.0  -1.158233   0.877737  1.548718  0.403034 -0.407193   \n...          ...        ...        ...       ...       ...       ...   \n284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n\n              V6        V7        V8        V9  ...       V21       V22  \\\n0       0.462388  0.239599  0.098698  0.363787  ... -0.018307  0.277838   \n1      -0.082361 -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672   \n2       1.800499  0.791461  0.247676 -1.514654  ...  0.247998  0.771679   \n3       1.247203  0.237609  0.377436 -1.387024  ... -0.108300  0.005274   \n4       0.095921  0.592941 -0.270533  0.817739  ... -0.009431  0.798278   \n...          ...       ...       ...       ...  ...       ...       ...   \n284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n\n             V23       V24       V25       V26       V27       V28  Amount  \\\n0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62   \n1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69   \n2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66   \n3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50   \n4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153   69.99   \n...          ...       ...       ...       ...       ...       ...     ...   \n284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n\n        Class  \n0           0  \n1           0  \n2           0  \n3           0  \n4           0  \n...       ...  \n284802      0  \n284803      0  \n284804      0  \n284805      0  \n284806      0  \n\n[284807 rows x 31 columns]>\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"class VAE(nn.Module):\n    def __init__(self, input_dim=29, hidden_dim=16, latent_dim=8):\n        super(VAE, self).__init__()\n        \n        # Encoder\n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim*2),\n            nn.ReLU(),\n            nn.Linear(hidden_dim*2, hidden_dim),\n            nn.ReLU()\n        )\n        \n        # Latent space\n        self.fc_mu = nn.Linear(hidden_dim, latent_dim)\n        self.fc_var = nn.Linear(hidden_dim, latent_dim)\n        \n        # Decoder\n        self.decoder = nn.Sequential(\n            nn.Linear(latent_dim, hidden_dim),\n            nn.ReLU(),\n            nn.Linear(hidden_dim, hidden_dim*2),\n            nn.ReLU(),\n            nn.Linear(hidden_dim*2, input_dim)\n        )\n        \n    def encode(self, x):\n        h = self.encoder(x)\n        return self.fc_mu(h), self.fc_var(h)\n    \n    def reparameterize(self, mu, log_var):\n        std = torch.exp(0.5 * log_var)\n        eps = torch.randn_like(std)\n        return mu + eps * std\n    \n    def decode(self, z):\n        return self.decoder(z)\n    \n    def forward(self, x):\n        mu, log_var = self.encode(x)\n        z = self.reparameterize(mu, log_var)\n        return self.decode(z), mu, log_var\n\ndef train_vae(df, epochs=50, batch_size=128, learning_rate=1e-3):\n    # Prepare data\n    features = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', \n                'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n                'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n    \n    # Scale the features\n    scaler = StandardScaler()\n    X = scaler.fit_transform(df[features].values)\n    \n    # Convert to PyTorch tensors\n    X_tensor = torch.FloatTensor(X)\n    \n    # Create data loader\n    dataset = TensorDataset(X_tensor)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n    \n    # Initialize model and optimizer\n    model = VAE(input_dim=len(features))\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n    \n    # Training loop\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        for batch_idx, (data,) in enumerate(dataloader):\n            optimizer.zero_grad()\n            \n            # Forward pass\n            recon_batch, mu, log_var = model(data)\n            \n            # Reconstruction loss\n            recon_loss = F.mse_loss(recon_batch, data, reduction='sum')\n            \n            # KL divergence loss\n            kl_loss = -0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp())\n            \n            # Total loss\n            loss = recon_loss + kl_loss\n            \n            # Backward pass\n            loss.backward()\n            optimizer.step()\n            \n            total_loss += loss.item()\n            \n        avg_loss = total_loss / len(dataloader.dataset)\n        if (epoch + 1) % 10 == 0:\n            print(f'Epoch [{epoch+1}/{epochs}], Average Loss: {avg_loss:.4f}')\n    \n    return model, scaler\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T17:07:31.532016Z","iopub.execute_input":"2025-02-20T17:07:31.533070Z","iopub.status.idle":"2025-02-20T17:07:31.554112Z","shell.execute_reply.started":"2025-02-20T17:07:31.533006Z","shell.execute_reply":"2025-02-20T17:07:31.552650Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"def detect_anomalies(model, df, scaler, threshold_percentile=95):\n    model.eval()\n    features = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', \n                'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21',\n                'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28', 'Amount']\n    \n    # Scale the data\n    X = scaler.transform(df[features].values)\n    X_tensor = torch.FloatTensor(X)\n    \n    with torch.no_grad():\n        recon_X, _, _ = model(X_tensor)\n    \n    # Calculate reconstruction error\n    reconstruction_errors = torch.mean((X_tensor - recon_X) ** 2, dim=1)\n    \n    # Set threshold based on percentile\n    threshold = np.percentile(reconstruction_errors.numpy(), threshold_percentile)\n    \n    # Flag anomalies\n    anomalies = reconstruction_errors > threshold\n    \n    return anomalies.numpy(), reconstruction_errors.numpy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nmodel, scaler = train_vae(df, epochs=50, batch_size=128)\n\n# Detect anomalies\nanomalies, reconstruction_errors = detect_anomalies(model, df, scaler)\n\n# Print results\nprint(f\"Number of anomalies detected: {sum(anomalies)}\")\nprint(f\"Percentage of anomalies: {(sum(anomalies)/len(anomalies))*100:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-20T17:07:40.218170Z","iopub.execute_input":"2025-02-20T17:07:40.218582Z","iopub.status.idle":"2025-02-20T17:15:47.711655Z","shell.execute_reply.started":"2025-02-20T17:07:40.218514Z","shell.execute_reply":"2025-02-20T17:15:47.710316Z"}},"outputs":[{"name":"stdout","text":"Epoch [10/50], Average Loss: 19.3509\nEpoch [20/50], Average Loss: 18.3026\nEpoch [30/50], Average Loss: 18.0777\nEpoch [40/50], Average Loss: 17.9263\nEpoch [50/50], Average Loss: 17.7928\nNumber of anomalies detected: 14241\nPercentage of anomalies: 5.00%\n","output_type":"stream"}],"execution_count":11}]}